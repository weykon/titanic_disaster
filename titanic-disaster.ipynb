{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nimport tensorflow as tf\nimport tensorflow_decision_forests as tfdf\n\nprint(f\"Found TF-DF {tfdf.__version__}\")\n\n\ntrain_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nserving_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\ntrain_df.head(10)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-24T05:39:23.938891Z","iopub.execute_input":"2023-11-24T05:39:23.939396Z","iopub.status.idle":"2023-11-24T05:39:37.979285Z","shell.execute_reply.started":"2023-11-24T05:39:23.939351Z","shell.execute_reply":"2023-11-24T05:39:37.977744Z"},"editable":false,"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found TF-DF 1.5.0\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n5            6         0       3   \n6            7         0       1   \n7            8         0       3   \n8            9         1       3   \n9           10         1       2   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n5                                   Moran, Mr. James    male   NaN      0   \n6                            McCarthy, Mr. Timothy J    male  54.0      0   \n7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n5      0            330877   8.4583   NaN        Q  \n6      0             17463  51.8625   E46        S  \n7      1            349909  21.0750   NaN        S  \n8      2            347742  11.1333   NaN        S  \n9      0            237736  30.0708   NaN        C  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Moran, Mr. James</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330877</td>\n      <td>8.4583</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>McCarthy, Mr. Timothy J</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17463</td>\n      <td>51.8625</td>\n      <td>E46</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Palsson, Master. Gosta Leonard</td>\n      <td>male</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>349909</td>\n      <td>21.0750</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n      <td>female</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>347742</td>\n      <td>11.1333</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>237736</td>\n      <td>30.0708</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"看看数据长什么样，\n然后有3个函数\n\n1. 一个规则化name\n2.","metadata":{"editable":false}},{"cell_type":"code","source":"def preprocess(df):\n    df = df.copy()\n    \n    def normalize_name(x):\n        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n    \n    def ticket_number(x):\n        return x.split(\" \")[-1]\n        \n    def ticket_item(x):\n        items = x.split(\" \")\n        if len(items) == 1:\n            return \"NONE\"\n        return \"_\".join(items[0:-1])\n    \n    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)                     \n    return df\n    \npreprocessed_train_df = preprocess(train_df)\npreprocessed_serving_df = preprocess(serving_df)\n\npreprocessed_train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:39:37.981814Z","iopub.execute_input":"2023-11-24T05:39:37.982356Z","iopub.status.idle":"2023-11-24T05:39:38.026569Z","shell.execute_reply.started":"2023-11-24T05:39:37.982318Z","shell.execute_reply":"2023-11-24T05:39:38.025306Z"},"editable":false,"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                              Name     Sex   Age  SibSp  \\\n0                            Braund Mr Owen Harris    male  22.0      1   \n1  Cumings Mrs John Bradley Florence Briggs Thayer  female  38.0      1   \n2                             Heikkinen Miss Laina  female  26.0      0   \n3         Futrelle Mrs Jacques Heath Lily May Peel  female  35.0      1   \n4                           Allen Mr William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked Ticket_number Ticket_item  \n0      0         A/5 21171   7.2500   NaN        S         21171         A/5  \n1      0          PC 17599  71.2833   C85        C         17599          PC  \n2      0  STON/O2. 3101282   7.9250   NaN        S       3101282    STON/O2.  \n3      0            113803  53.1000  C123        S        113803        NONE  \n4      0            373450   8.0500   NaN        S        373450        NONE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Ticket_number</th>\n      <th>Ticket_item</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund Mr Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>21171</td>\n      <td>A/5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings Mrs John Bradley Florence Briggs Thayer</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>17599</td>\n      <td>PC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen Miss Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3101282</td>\n      <td>STON/O2.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle Mrs Jacques Heath Lily May Peel</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>113803</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen Mr William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>373450</td>\n      <td>NONE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"去掉一些对于模型的想法的不必要内容\n买什么票和分给他的id和生还，与否先不管。\n是train的数据集","metadata":{"editable":false}},{"cell_type":"code","source":"input_features = list(preprocessed_train_df.columns)\ninput_features.remove(\"Ticket\")\ninput_features.remove(\"PassengerId\")\ninput_features.remove(\"Survived\")\n#input_features.remove(\"Ticket_number\")\n\nprint(f\"Input features: {input_features}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:39:38.028927Z","iopub.execute_input":"2023-11-24T05:39:38.030329Z","iopub.status.idle":"2023-11-24T05:39:38.098869Z","shell.execute_reply.started":"2023-11-24T05:39:38.030278Z","shell.execute_reply":"2023-11-24T05:39:38.097668Z"},"editable":false,"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Input features: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Ticket_number', 'Ticket_item']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"那么现在是主要探究，（一些名称不知道是什么😓）\n\npd呢，做了一些普通的数学，现在把数据放入tf试试","metadata":{"editable":false}},{"cell_type":"code","source":"# 现在我这个就看得懂，tokenize嘛，以前怎么看都不懂\ndef tokenize_names(features, labels=None):\n    \"\"\"Divite the names into tokens. TF-DF can consume text tokens natively.\"\"\"\n    features[\"Name\"] =  tf.strings.split(features[\"Name\"])\n    return features, labels\n\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_train_df,label=\"Survived\").map(tokenize_names)\nserving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(tokenize_names)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:39:38.100125Z","iopub.execute_input":"2023-11-24T05:39:38.100625Z","iopub.status.idle":"2023-11-24T05:39:38.643660Z","shell.execute_reply.started":"2023-11-24T05:39:38.100584Z","shell.execute_reply":"2023-11-24T05:39:38.642354Z"},"editable":false,"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"上面这个开始魔了，features我们类比为x， label是标签作结果为y。\n\n然后这里是一个特别的地方是 tf 自己的strings split，我称为他作信息量化，把数据中名字token化。\n\n后面两句，为什么pd的dataframe不能和tf的dataset一样名字的概念啊\n\ntrain_ds 用于模型训练，而 serving_ds 可能用于模型的推理或评估","metadata":{"editable":false}},{"cell_type":"markdown","source":"","metadata":{"editable":false}},{"cell_type":"markdown","source":"下面， 我服了，无端端搞个梯度增压（瞎搞名字）模型，我理解为一群羊来到了一个树林，全部赶进去，羊崽们自己爱怎么走就怎么走，可能跟地形，风景啊相关，不过我们看看最终结果就可以了。","metadata":{"editable":false}},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, # Very few logs\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True, # Only use the features in \"features\"\n    random_seed=1234,\n)\nmodel.fit(train_ds)\n\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:39:38.646759Z","iopub.execute_input":"2023-11-24T05:39:38.647122Z","iopub.status.idle":"2023-11-24T05:39:50.642990Z","shell.execute_reply.started":"2023-11-24T05:39:38.647091Z","shell.execute_reply":"2023-11-24T05:39:50.641596Z"},"editable":false,"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"[WARNING 23-11-24 05:39:38.7010 UTC gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-11-24 05:39:38.7013 UTC gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-11-24 05:39:38.7015 UTC gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 23-11-24 05:39:46.6522 UTC kernel.cc:1243] Loading model from path /tmp/tmpx36uq8r5/model/ with prefix 868abcce98ab4439\n[INFO 23-11-24 05:39:46.6649 UTC abstract_model.cc:1311] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n[INFO 23-11-24 05:39:46.6651 UTC kernel.cc:1075] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7eb660db9c60> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: could not get source code\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nAccuracy: 0.8260869383811951 Loss:0.8608942627906799\n","output_type":"stream"}]},{"cell_type":"markdown","source":"下面的是加了很多参数去试试","metadata":{"editable":false}},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, # Very few logs\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True, # Only use the features in \"features\"\n    \n    #num_trees=2000,\n    \n    # Only for GBT.\n    # A bit slower, but great to understand the model.\n    # compute_permutation_variable_importance=True,\n    \n    # Change the default hyper-parameters\n    # hyperparameter_template=\"benchmark_rank1@v1\",\n    \n    #num_trees=1000,\n    #tuner=tuner\n    \n    min_examples=1,\n    categorical_algorithm=\"RANDOM\",\n    #max_depth=4,\n    shrinkage=0.05,\n    #num_candidate_attributes_ratio=0.2,\n    split_axis=\"SPARSE_OBLIQUE\",\n    sparse_oblique_normalization=\"MIN_MAX\",\n    sparse_oblique_num_projections_exponent=2.0,\n    num_trees=2000,\n    #validation_ratio=0.0,\n    random_seed=1234,\n    \n)\nmodel.fit(train_ds)\n\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:39:50.644508Z","iopub.execute_input":"2023-11-24T05:39:50.644852Z","iopub.status.idle":"2023-11-24T05:39:52.262015Z","shell.execute_reply.started":"2023-11-24T05:39:50.644822Z","shell.execute_reply":"2023-11-24T05:39:52.260495Z"},"editable":false,"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"[WARNING 23-11-24 05:39:50.6620 UTC gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-11-24 05:39:50.6620 UTC gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-11-24 05:39:50.6620 UTC gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 23-11-24 05:39:51.8727 UTC kernel.cc:1243] Loading model from path /tmp/tmphzz3l8y8/model/ with prefix 489d63b5a3e14783\n[INFO 23-11-24 05:39:51.8836 UTC decision_forest.cc:660] Model loaded with 42 root(s), 2212 node(s), and 10 input feature(s).\n[INFO 23-11-24 05:39:51.8838 UTC kernel.cc:1075] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.782608687877655 Loss:1.060815453529358\n","output_type":"stream"}]},{"cell_type":"markdown","source":"下面看看情况","metadata":{"editable":false}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:39:52.264235Z","iopub.execute_input":"2023-11-24T05:39:52.264769Z","iopub.status.idle":"2023-11-24T05:39:52.283004Z","shell.execute_reply.started":"2023-11-24T05:39:52.264722Z","shell.execute_reply":"2023-11-24T05:39:52.281584Z"},"editable":false,"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"gradient_boosted_trees_model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n=================================================================\nTotal params: 1 (1.00 Byte)\nTrainable params: 0 (0.00 Byte)\nNon-trainable params: 1 (1.00 Byte)\n_________________________________________________________________\nType: \"GRADIENT_BOOSTED_TREES\"\nTask: CLASSIFICATION\nLabel: \"__LABEL\"\n\nInput Features (11):\n\tAge\n\tCabin\n\tEmbarked\n\tFare\n\tName\n\tParch\n\tPclass\n\tSex\n\tSibSp\n\tTicket_item\n\tTicket_number\n\nNo weights\n\nVariable Importance: INV_MEAN_MIN_DEPTH:\n    1.           \"Sex\"  0.597073 ################\n    2.           \"Age\"  0.363764 #######\n    3.          \"Fare\"  0.264018 ###\n    4.          \"Name\"  0.207843 #\n    5.        \"Pclass\"  0.178906 \n    6. \"Ticket_number\"  0.178488 \n    7.   \"Ticket_item\"  0.177907 \n    8.      \"Embarked\"  0.177237 \n    9.         \"Parch\"  0.175481 \n   10.         \"SibSp\"  0.171800 \n\nVariable Importance: NUM_AS_ROOT:\n    1.  \"Sex\" 36.000000 ################\n    2. \"Name\"  6.000000 \n\nVariable Importance: NUM_NODES:\n    1.           \"Age\" 530.000000 ################\n    2.          \"Fare\" 311.000000 #########\n    3.          \"Name\" 66.000000 #\n    4.   \"Ticket_item\" 50.000000 #\n    5.           \"Sex\" 42.000000 #\n    6.         \"Parch\" 26.000000 \n    7. \"Ticket_number\" 21.000000 \n    8.        \"Pclass\" 17.000000 \n    9.      \"Embarked\" 16.000000 \n   10.         \"SibSp\"  6.000000 \n\nVariable Importance: SUM_SCORE:\n    1.           \"Sex\" 484.272240 ################\n    2.           \"Age\" 393.999352 #############\n    3.          \"Fare\" 323.250985 ##########\n    4.          \"Name\" 105.330212 ###\n    5.        \"Pclass\" 26.851849 \n    6.   \"Ticket_item\" 25.837695 \n    7. \"Ticket_number\" 17.652836 \n    8.      \"Embarked\"  9.217001 \n    9.         \"Parch\"  7.010211 \n   10.         \"SibSp\"  0.574055 \n\n\n\nLoss: BINOMIAL_LOG_LIKELIHOOD\nValidation loss value: 1.06082\nNumber of trees per iteration: 1\nNode format: NOT_SET\nNumber of trees: 42\nTotal number of nodes: 2212\n\nNumber of nodes by tree:\nCount: 42 Average: 52.6667 StdDev: 4.47036\nMin: 41 Max: 63 Ignored: 0\n----------------------------------------------\n[ 41, 42)  2   4.76%   4.76% ##\n[ 42, 43)  0   0.00%   4.76%\n[ 43, 44)  0   0.00%   4.76%\n[ 44, 45)  0   0.00%   4.76%\n[ 45, 46)  1   2.38%   7.14% #\n[ 46, 47)  0   0.00%   7.14%\n[ 47, 49)  2   4.76%  11.90% ##\n[ 49, 50)  5  11.90%  23.81% ####\n[ 50, 51)  0   0.00%  23.81%\n[ 51, 52)  4   9.52%  33.33% ###\n[ 52, 53)  0   0.00%  33.33%\n[ 53, 54) 13  30.95%  64.29% ##########\n[ 54, 55)  0   0.00%  64.29%\n[ 55, 57)  9  21.43%  85.71% #######\n[ 57, 58)  1   2.38%  88.10% #\n[ 58, 59)  0   0.00%  88.10%\n[ 59, 60)  3   7.14%  95.24% ##\n[ 60, 61)  0   0.00%  95.24%\n[ 61, 62)  1   2.38%  97.62% #\n[ 62, 63]  1   2.38% 100.00% #\n\nDepth by leafs:\nCount: 1127 Average: 4.8465 StdDev: 0.454147\nMin: 2 Max: 5 Ignored: 0\n----------------------------------------------\n[ 2, 3)   1   0.09%   0.09%\n[ 3, 4)  40   3.55%   3.64%\n[ 4, 5)  90   7.99%  11.62% #\n[ 5, 5] 996  88.38% 100.00% ##########\n\nNumber of training obs by leaf:\nCount: 1127 Average: 29.7764 StdDev: 71.9364\nMin: 1 Max: 467 Ignored: 0\n----------------------------------------------\n[   1,  24) 884  78.44%  78.44% ##########\n[  24,  47)  79   7.01%  85.45% #\n[  47,  71)  44   3.90%  89.35%\n[  71,  94)  19   1.69%  91.04%\n[  94, 117)  13   1.15%  92.19%\n[ 117, 141)  15   1.33%  93.52%\n[ 141, 164)  24   2.13%  95.65%\n[ 164, 187)   6   0.53%  96.18%\n[ 187, 211)   4   0.35%  96.54%\n[ 211, 234)   1   0.09%  96.63%\n[ 234, 257)   1   0.09%  96.72%\n[ 257, 281)   3   0.27%  96.98%\n[ 281, 304)   2   0.18%  97.16%\n[ 304, 327)   2   0.18%  97.34%\n[ 327, 351)   2   0.18%  97.52%\n[ 351, 374)  11   0.98%  98.49%\n[ 374, 397)   5   0.44%  98.94%\n[ 397, 421)   9   0.80%  99.73%\n[ 421, 444)   1   0.09%  99.82%\n[ 444, 467]   2   0.18% 100.00%\n\nAttribute in nodes:\n\t530 : Age [NUMERICAL]\n\t311 : Fare [NUMERICAL]\n\t66 : Name [CATEGORICAL_SET]\n\t50 : Ticket_item [CATEGORICAL]\n\t42 : Sex [CATEGORICAL]\n\t26 : Parch [NUMERICAL]\n\t21 : Ticket_number [CATEGORICAL]\n\t17 : Pclass [NUMERICAL]\n\t16 : Embarked [CATEGORICAL]\n\t6 : SibSp [NUMERICAL]\n\nAttribute in nodes with depth <= 0:\n\t36 : Sex [CATEGORICAL]\n\t6 : Name [CATEGORICAL_SET]\n\nAttribute in nodes with depth <= 1:\n\t50 : Age [NUMERICAL]\n\t36 : Sex [CATEGORICAL]\n\t26 : Fare [NUMERICAL]\n\t7 : Name [CATEGORICAL_SET]\n\t5 : Pclass [NUMERICAL]\n\t2 : Ticket_number [CATEGORICAL]\n\nAttribute in nodes with depth <= 2:\n\t130 : Age [NUMERICAL]\n\t76 : Fare [NUMERICAL]\n\t36 : Sex [CATEGORICAL]\n\t19 : Name [CATEGORICAL_SET]\n\t8 : Ticket_number [CATEGORICAL]\n\t7 : Embarked [CATEGORICAL]\n\t6 : Pclass [NUMERICAL]\n\t6 : Parch [NUMERICAL]\n\t5 : Ticket_item [CATEGORICAL]\n\nAttribute in nodes with depth <= 3:\n\t270 : Age [NUMERICAL]\n\t173 : Fare [NUMERICAL]\n\t39 : Name [CATEGORICAL_SET]\n\t38 : Sex [CATEGORICAL]\n\t18 : Ticket_item [CATEGORICAL]\n\t13 : Ticket_number [CATEGORICAL]\n\t12 : Parch [NUMERICAL]\n\t12 : Embarked [CATEGORICAL]\n\t9 : Pclass [NUMERICAL]\n\t3 : SibSp [NUMERICAL]\n\nAttribute in nodes with depth <= 5:\n\t530 : Age [NUMERICAL]\n\t311 : Fare [NUMERICAL]\n\t66 : Name [CATEGORICAL_SET]\n\t50 : Ticket_item [CATEGORICAL]\n\t42 : Sex [CATEGORICAL]\n\t26 : Parch [NUMERICAL]\n\t21 : Ticket_number [CATEGORICAL]\n\t17 : Pclass [NUMERICAL]\n\t16 : Embarked [CATEGORICAL]\n\t6 : SibSp [NUMERICAL]\n\nCondition type in nodes:\n\t890 : ObliqueCondition\n\t145 : ContainsBitmapCondition\n\t50 : ContainsCondition\nCondition type in nodes with depth <= 0:\n\t40 : ContainsBitmapCondition\n\t2 : ContainsCondition\nCondition type in nodes with depth <= 1:\n\t81 : ObliqueCondition\n\t43 : ContainsBitmapCondition\n\t2 : ContainsCondition\nCondition type in nodes with depth <= 2:\n\t218 : ObliqueCondition\n\t62 : ContainsBitmapCondition\n\t13 : ContainsCondition\nCondition type in nodes with depth <= 3:\n\t467 : ObliqueCondition\n\t89 : ContainsBitmapCondition\n\t31 : ContainsCondition\nCondition type in nodes with depth <= 5:\n\t890 : ObliqueCondition\n\t145 : ContainsBitmapCondition\n\t50 : ContainsCondition\n\nTraining logs:\nNumber of iteration to final model: 42\n\tIter:1 train-loss:1.264594 valid-loss:1.360749  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:2 train-loss:1.210623 valid-loss:1.320363  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:3 train-loss:1.160657 valid-loss:1.281972  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:4 train-loss:1.116982 valid-loss:1.250548  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:5 train-loss:1.075170 valid-loss:1.221467  train-accuracy:0.807259 valid-accuracy:0.760870\n\tIter:6 train-loss:1.035656 valid-loss:1.199482  train-accuracy:0.822278 valid-accuracy:0.760870\n\tIter:16 train-loss:0.787670 valid-loss:1.088161  train-accuracy:0.903630 valid-accuracy:0.771739\n\tIter:26 train-loss:0.648139 valid-loss:1.066864  train-accuracy:0.921151 valid-accuracy:0.782609\n\tIter:36 train-loss:0.559101 valid-loss:1.068122  train-accuracy:0.921151 valid-accuracy:0.782609\n\tIter:46 train-loss:0.496837 valid-loss:1.064204  train-accuracy:0.929912 valid-accuracy:0.771739\n\tIter:56 train-loss:0.451017 valid-loss:1.083011  train-accuracy:0.941176 valid-accuracy:0.771739\n\tIter:66 train-loss:0.415965 valid-loss:1.105307  train-accuracy:0.946183 valid-accuracy:0.771739\n\n","output_type":"stream"}]}]}