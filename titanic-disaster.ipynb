{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nimport tensorflow as tf\nimport tensorflow_decision_forests as tfdf\n\nprint(f\"Found TF-DF {tfdf.__version__}\")\n\n\ntrain_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nserving_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\ntrain_df.head(10)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-24T05:39:23.938891Z","iopub.execute_input":"2023-11-24T05:39:23.939396Z","iopub.status.idle":"2023-11-24T05:39:37.979285Z","shell.execute_reply.started":"2023-11-24T05:39:23.939351Z","shell.execute_reply":"2023-11-24T05:39:37.977744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"看看数据长什么样，\n然后有3个函数\n\n1. 一个规则化name\n2. python的数组-1 index 是指到最后一个元素\n","metadata":{}},{"cell_type":"code","source":"def preprocess(df):\n    df = df.copy()\n    \n    def normalize_name(x):\n        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n    \n    def ticket_number(x):\n        return x.split(\" \")[-1]\n        \n    def ticket_item(x):\n        items = x.split(\" \")\n        if len(items) == 1:\n            return \"NONE\"\n        return \"_\".join(items[0:-1])\n    \n    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)                     \n    return df\n    \npreprocessed_train_df = preprocess(train_df)\npreprocessed_serving_df = preprocess(serving_df)\n\npreprocessed_train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:39:37.981814Z","iopub.execute_input":"2023-11-24T05:39:37.982356Z","iopub.status.idle":"2023-11-24T05:39:38.026569Z","shell.execute_reply.started":"2023-11-24T05:39:37.982318Z","shell.execute_reply":"2023-11-24T05:39:38.025306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"去掉一些对于模型的想法的不必要内容\n买什么票和分给他的id和生还，与否先不管。\n是train的数据集","metadata":{}},{"cell_type":"code","source":"input_features = list(preprocessed_train_df.columns)\ninput_features.remove(\"Ticket\")\ninput_features.remove(\"PassengerId\")\ninput_features.remove(\"Survived\")\n#input_features.remove(\"Ticket_number\")\n\nprint(f\"Input features: {input_features}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:39:38.028927Z","iopub.execute_input":"2023-11-24T05:39:38.030329Z","iopub.status.idle":"2023-11-24T05:39:38.098869Z","shell.execute_reply.started":"2023-11-24T05:39:38.030278Z","shell.execute_reply":"2023-11-24T05:39:38.097668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"那么现在是主要探究，（一些名称不知道是什么😓）\n\npd呢，做了一些普通的数学，现在把数据放入tf试试","metadata":{}},{"cell_type":"code","source":"# 现在我这个就看得懂，tokenize嘛，以前怎么看都不懂\ndef tokenize_names(features, labels=None):\n    \"\"\"Divite the names into tokens. TF-DF can consume text tokens natively.\"\"\"\n    features[\"Name\"] =  tf.strings.split(features[\"Name\"])\n    return features, labels\n\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_train_df,label=\"Survived\").map(tokenize_names)\nserving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(tokenize_names)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:39:38.100125Z","iopub.execute_input":"2023-11-24T05:39:38.100625Z","iopub.status.idle":"2023-11-24T05:39:38.643660Z","shell.execute_reply.started":"2023-11-24T05:39:38.100584Z","shell.execute_reply":"2023-11-24T05:39:38.642354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"上面这个开始魔了，features我们类比为x， label是标签作结果为y。\n\n然后这里是一个特别的地方是 tf 自己的strings split，我称为他作信息量化，把数据中名字token化。\n\n后面两句，为什么pd的dataframe不能和tf的dataset一样名字的概念啊\n\ntrain_ds 用于模型训练，而 serving_ds 可能用于模型的推理或评估","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"下面， 我服了，无端端搞个梯度增压（瞎搞名字）模型，我理解为一群羊来到了一个树林，全部赶进去，羊崽们自己爱怎么走就怎么走，可能跟地形，风景啊相关，不过我们看看最终结果就可以了。","metadata":{}},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, # Very few logs\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True, # Only use the features in \"features\"\n    random_seed=1234,\n)\nmodel.fit(train_ds)\n\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:39:38.646759Z","iopub.execute_input":"2023-11-24T05:39:38.647122Z","iopub.status.idle":"2023-11-24T05:39:50.642990Z","shell.execute_reply.started":"2023-11-24T05:39:38.647091Z","shell.execute_reply":"2023-11-24T05:39:50.641596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"下面的是加了很多参数去试试","metadata":{}},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, # Very few logs\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True, # Only use the features in \"features\"\n    \n    #num_trees=2000,\n    \n    # Only for GBT.\n    # A bit slower, but great to understand the model.\n    # compute_permutation_variable_importance=True,\n    \n    # Change the default hyper-parameters\n    # hyperparameter_template=\"benchmark_rank1@v1\",\n    \n    #num_trees=1000,\n    #tuner=tuner\n    \n    min_examples=1,\n    categorical_algorithm=\"RANDOM\",\n    #max_depth=4,\n    shrinkage=0.05,\n    #num_candidate_attributes_ratio=0.2,\n    split_axis=\"SPARSE_OBLIQUE\",\n    sparse_oblique_normalization=\"MIN_MAX\",\n    sparse_oblique_num_projections_exponent=2.0,\n    num_trees=2000,\n    #validation_ratio=0.0,\n    random_seed=1234,\n    \n)\nmodel.fit(train_ds)\n\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:39:50.644508Z","iopub.execute_input":"2023-11-24T05:39:50.644852Z","iopub.status.idle":"2023-11-24T05:39:52.262015Z","shell.execute_reply.started":"2023-11-24T05:39:50.644822Z","shell.execute_reply":"2023-11-24T05:39:52.260495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"下面看看情况，稍微看一点点对于这些参数的大概讲解。\n\n> 先来一个个人思考。随机的策略下，收紧的5% ……\n\n上面这个人的思考，完全不搭边。\n\n我再大概说一次。选材features，把表单的里面都选进来，最低限度在一个样本及以后都去烹饪，在慢慢细嚼慢熬的每个以5%的占用影响率去反馈结果，所以需要熬的时间长一些，冒泡反馈的次数多一些。\n\n对于其他的参数，\"SPARSE_OBLIQUE\"，稀稀拉拉的偏斜。\n多个features来决定，我有一个想象的场景是，每个不同的feature是一个不同方向的向量，长度也不一样，而多个feature结合出来的这一个矩阵或者说几何形状吧，他们这个时候就是一个结晶点，是计算过程中的一个控制器。\n\n那我设计一个小鸡走移动迷宫，这个移动迷宫是有意识的，不过它自己也不知道迷宫的出口在哪里，而且是很多很多的小鸡走出出口的口口相传之后，迷宫才会发生变化。所以，当遇到这个\"sparse_oblique\"的时候，当小鸡的身型和颜色等等的各种特性，它不是每次都全部把这种特性算进去计算，而是都留一些在下一个分岔口去选择决定。","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:39:52.264235Z","iopub.execute_input":"2023-11-24T05:39:52.264769Z","iopub.status.idle":"2023-11-24T05:39:52.283004Z","shell.execute_reply.started":"2023-11-24T05:39:52.264722Z","shell.execute_reply":"2023-11-24T05:39:52.281584Z"},"trusted":true},"execution_count":null,"outputs":[]}]}